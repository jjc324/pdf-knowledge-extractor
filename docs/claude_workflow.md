# Claude Integration Workflow

This guide demonstrates the complete workflow for processing PDFs through Claude using the PDF Knowledge Extractor.

## Overview

The Claude integration provides intelligent batch processing of PDFs with:
- **Automatic context window management** - Handles large documents by chunking
- **Smart retry logic** - Exponential backoff for failed analyses  
- **Structured output** - Consistent markdown formatting like batch1.md/batch2.md
- **Cross-referencing** - Automatic linking between related documents
- **Progress tracking** - Saves state between sessions for resumption
- **Comprehensive error handling** - Detailed logging and error reporting

## Complete Workflow

### Step 1: Analyze PDFs (Generate processable_pdfs.json)

First, run the PDF analysis to identify which documents can be processed:

```bash
# Analyze a directory of PDFs
pdf-extract /path/to/pdf/directory --mode analyze --output ./results

# With custom limits
pdf-extract /path/to/pdf/directory --max-size 25 --max-pages 200 --recursive --output ./results
```

This generates:
- `processable_pdfs.json` - Documents suitable for processing
- `special_handling_pdfs.json` - Large documents requiring special handling
- `pdf_analysis_errors.json` - Documents that couldn't be analyzed

### Step 2: Claude Batch Processing

Process the analyzed PDFs through Claude:

```bash
# Basic Claude batch processing
pdf-extract /path/to/pdf/directory --mode claude-batch --output ./claude_results

# With custom settings
pdf-extract /path/to/pdf/directory --mode claude-batch \
  --batch-size 5 \
  --max-retries 3 \
  --output ./claude_results \
  --verbose
```

### Step 3: Resume Interrupted Processing

If processing is interrupted, resume from where it left off:

```bash
# Resume automatically from saved state
pdf-extract /path/to/pdf/directory --mode claude-batch --resume --output ./claude_results
```

## Output Structure

The Claude integration generates a comprehensive set of output files:

```
claude_results/
├── processing_summary.md              # Final summary of all processing
├── batch1_summary.md                  # Summary of first batch
├── batch2_summary.md                  # Summary of second batch
├── document1_analysis.md              # Individual document analysis
├── document2_analysis.md              # Individual document analysis
├── .claude_processing_state.json      # State file for resumption
└── .claude_progress.json              # Progress tracking
```

### Individual Document Analysis Format

Each document generates a structured markdown file similar to batch1.md/batch2.md:

```markdown
# Analysis: document_name.pdf

## Document Metadata
- **File**: `document_name.pdf`
- **Size**: 5.2 MB
- **Pages**: 45
- **Processing Date**: 2024-01-15T14:30:00
- **Token Estimate**: 12,450

## Analysis
[Claude's detailed analysis of the document content]

## Related Documents
- [related_document1.pdf](related_document1_analysis.md)
- [related_document2.pdf](related_document2_analysis.md)

---
*Generated by PDF Knowledge Extractor with Claude Integration*
```

### Batch Summary Format

Each batch generates a summary file:

```markdown
# Batch 1 Processing Summary

**Processing Date**: 2024-01-15 14:30:25
**Documents Processed**: 5
**Successful**: 5
**Failed**: 0
**Success Rate**: 100.0%

## Processed Documents

✅ **document1.pdf**
   - Size: 2.5 MB, Pages: 15
   - Tokens: 8,250
   - Output: [document1_analysis.md](document1_analysis.md)
   - Related: 2 documents

✅ **document2.pdf**
   - Size: 4.1 MB, Pages: 28
   - Tokens: 15,750
   - Output: [document2_analysis.md](document2_analysis.md)
   - Related: 3 documents

## Document Relationships
**document1.pdf**:
  - document3.pdf
  - document5.pdf

**document2.pdf**:
  - document1.pdf
  - document4.pdf
  - document6.pdf
```

## Advanced Configuration

### Claude-Specific Settings

```yaml
# config.yaml
claude:
  # Context window management
  max_tokens_per_request: 8000
  context_window_size: 200000
  
  # Batch processing
  batch_size: 5
  
  # Retry logic  
  max_retries: 3
  retry_delay_base: 2.0  # seconds (exponential backoff)
  
  # Output formatting
  output_format: markdown
  include_metadata: true
  include_cross_references: true

# Progress tracking
progress:
  enabled: true
  resume:
    enabled: true
    file_name: ".claude_processing_state.json"
    save_interval: 10
```

### Python API Usage

```python
from pdf_knowledge_extractor.claude_integration import ClaudeIntegration

# Initialize with configuration
config = {
    'claude': {
        'batch_size': 5,
        'max_retries': 3,
        'context_window_size': 200000
    },
    'progress': {'enabled': True}
}

claude_integration = ClaudeIntegration(config)

# Run batch processing
results = claude_integration.run_batch_processing(
    processable_pdfs_file="./results/processable_pdfs.json",
    output_dir="./claude_results",
    resume=True
)

print(f"Processing completed:")
print(f"  Total: {results['total_documents']}")
print(f"  Successful: {results['successful']}")
print(f"  Failed: {results['failed']}")
print(f"  Batches: {results['batches_processed']}")
```

## Context Window Management

The system automatically handles large documents:

### Automatic Chunking
- Documents exceeding 70% of context window are automatically chunked
- Intelligent chunking preserves sentence boundaries when possible
- Chunks are processed sequentially with progress tracking

### Token Estimation
- Estimates tokens using ~4 characters per token ratio
- Accounts for context window overhead
- Optimizes batch sizes based on total token counts

### Batch Optimization
- Groups documents to maximize context window usage
- Prioritizes smaller documents first for faster feedback
- Balances batch sizes to avoid timeout issues

## Cross-Reference Generation

### Keyword-Based Relationships
- Extracts meaningful keywords from each document (excluding stop words)
- Builds an index mapping keywords to documents
- Identifies related documents based on shared keywords

### Relationship Threshold
- Configurable minimum shared keywords for relationship detection
- Ranks relationships by keyword overlap strength
- Limits cross-references to top N related documents

### Output Integration
- Related documents are automatically linked in output files
- Batch summaries include relationship maps
- Final summary provides comprehensive cross-reference overview

## Error Handling and Retry Logic

### Smart Retry Strategy
- Exponential backoff: 2^attempt seconds delay
- Configurable maximum retry attempts
- Different handling for different error types

### Error Categories
- **Extraction Errors**: PDF reading/parsing issues
- **Processing Errors**: Claude API or analysis failures  
- **I/O Errors**: File system access issues
- **Configuration Errors**: Invalid settings or missing files

### Recovery Mechanisms
- Automatic state saving every N documents
- Resume capability from last successful state
- Detailed error logging for troubleshooting
- Graceful degradation for partial failures

## Performance Optimization

### Parallel Processing
- Batches are processed sequentially for reliability
- Individual document processing within batches
- Progress tracking with estimated completion times

### Memory Management
- Streaming text extraction for large documents
- Cleanup of processed document content
- Efficient keyword indexing with sets

### State Persistence
- Minimal state files for fast loading
- Compressed progress tracking
- Atomic state updates to prevent corruption

## Monitoring and Debugging

### Progress Tracking
```bash
# Monitor progress with verbose output
pdf-extract /path/to/pdfs --mode claude-batch --verbose --log-file claude.log

# Check processing state
ls -la ./claude_results/.claude_*
```

### Log Analysis
```bash
# View detailed logs
tail -f claude.log

# Check for errors
grep -i error claude.log

# Monitor progress
grep -i "completed\|processing\|batch" claude.log
```

### State Inspection
```python
import json

# Check processing state
with open('./claude_results/.claude_processing_state.json') as f:
    state = json.load(f)
    
print(f"Documents processed: {len(state['document_contexts'])}")
print(f"Batches completed: {len(state['processed_batches'])}")

# Check progress
with open('./claude_results/.claude_progress.json') as f:
    progress = json.load(f)
    
print(f"Progress: {progress['processed_documents']}/{progress['total_documents']}")
print(f"Estimated completion: {progress.get('estimated_completion', 'Unknown')}")
```

## Best Practices

### Pre-Processing
1. Run PDF analysis first to identify processable documents
2. Review special handling documents for manual processing
3. Configure appropriate size and page limits
4. Test with small batches before large-scale processing

### During Processing
1. Monitor progress with verbose logging
2. Ensure sufficient disk space for output files
3. Don't interrupt processing unnecessarily (state is saved automatically)
4. Review batch summaries as they're generated

### Post-Processing
1. Review final processing summary for failures
2. Check cross-references for accuracy
3. Validate output file completeness
4. Archive state files for future reference

### Troubleshooting
1. Check logs for specific error messages
2. Verify processable_pdfs.json exists and is valid
3. Ensure output directory is writable
4. Test individual document processing for debugging
5. Use resume capability after fixing issues

## Integration Examples

### Complete Workflow Script
```bash
#!/bin/bash

# Complete PDF processing workflow
PDF_DIR="/path/to/pdfs"
RESULTS_DIR="./results"
CLAUDE_DIR="./claude_results"

echo "Step 1: Analyzing PDFs..."
pdf-extract "$PDF_DIR" --mode analyze --recursive --output "$RESULTS_DIR"

echo "Step 2: Processing through Claude..."
pdf-extract "$PDF_DIR" --mode claude-batch --output "$CLAUDE_DIR" --verbose

echo "Step 3: Generating final report..."
echo "Processing complete! Check $CLAUDE_DIR/processing_summary.md for results."
```

### CI/CD Integration
```yaml
# .github/workflows/pdf-processing.yml
name: PDF Processing
on: [push]

jobs:
  process-pdfs:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -e .
    
    - name: Analyze PDFs
      run: |
        pdf-extract ./pdfs --mode analyze --output ./results
    
    - name: Process with Claude
      run: |
        pdf-extract ./pdfs --mode claude-batch --output ./claude-results
    
    - name: Upload results
      uses: actions/upload-artifact@v2
      with:
        name: pdf-analysis-results
        path: ./claude-results/
```

This comprehensive workflow ensures efficient, reliable, and resumable processing of PDF documents through Claude while maintaining detailed progress tracking and structured output formatting.